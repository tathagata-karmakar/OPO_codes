#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Created on Mon Jul 31 09:22:51 2023

@author: t_karmakar
"""

import os
import qutip as qt
import time
import matplotlib.pyplot as plt
import matplotlib as mpl
import numpy as np
from scipy.integrate import simps as intg
from matplotlib import rc
from pylab import rcParams
from FNO_structure import *
os.environ["PATH"] += os.pathsep + '/Library/TeX/texbin'
rc('text',usetex=True)

import jax
import jax.numpy as jnp
from jax import grad, jit, vmap
from jax import random
from jax import lax
from jax import device_put
from jax import make_jaxpr
from jax.scipy.special import logsumexp
from functools import partial
import collections 
from typing import Iterable

import tensorflow as tf
tf.config.set_visible_devices([],device_type='GPU')
import tensorflow_datasets as tfds

def random_layer_params(m,n,key,scale=1e-2):
    w_key,b_key=random.split(key)
    return scale*random.normal(w_key,(n,m)),scale*random.normal(b_key,(n,))
def init_network_params(sizes,key):
    keys=random.split(key,len(sizes))
    return [random_layer_params(m,n,k) for m,n,k in zip(sizes[:-1],sizes[1:],keys)]

def relu(x):
    return jnp.maximum(0,x)

def predict(params, image):
    activations =image
    for w,b in params[:-1]:
        outputs = jnp.dot(w,activations)+b
        activations = relu(outputs)
    final_w,final_b=params[-1]
    logits=jnp.dot(final_w,activations)+final_b
    return logits - logsumexp(logits)

def one_hot(x,k,dtype=jnp.float32):
    return jnp.array(x[:, None] == jnp.arange(k),dtype)

def accuracy(params, images, targets):
    target_class = jnp.argmax(targets,axis=1)
    predicted_class = jnp.argmax(batched_predict(params,images),axis=1)
    return jnp.mean(predicted_class == target_class)

def loss(params, images, targets):
    preds = batched_predict(params, images)
    return -jnp.mean(preds * targets)

@jit 
def update(params, x, y):
    grads = grad(loss)(params, x, y)
    return [(w-step_size*dw,b-step_size*db) for (w,b), (dw, db) in zip(params, grads)]

layer_sizes=[784,512,512,10]
step_size=0.01
num_epochs=10
batch_size=128
n_targets=10
params=init_network_params(layer_sizes,random.PRNGKey(0))

batched_predict = vmap(predict,in_axes=(None,0))

data_dir = '/tmp/tfds'

mnist_data, info = tfds.load(name="mnist",batch_size=-1, data_dir= data_dir, with_info=True)
mnist_data=tfds.as_numpy(mnist_data)
train_data,test_data=mnist_data['train'],mnist_data['test']
num_labels=info.features['label'].num_classes
h,w,c=info.features['image'].shape
num_pixels=h*w*c

train_images,train_labels = train_data['image'],train_data['label']
train_images = jnp.reshape(train_images,(len(train_images), num_pixels))
train_labels = one_hot(train_labels, num_labels)

test_images, test_labels = test_data['image'],test_data['label']
test_images = jnp.reshape(test_images,(len(test_images), num_pixels))
test_labels = one_hot(test_labels, num_labels)

print('Train:', train_images.shape, train_labels.shape)
print('Test:', test_images.shape, test_labels.shape)

def get_train_batches():
    ds = tfds.load(name='mnist',split='train, as_supervised=True',data_dir=data_dir)
    ds = ds.batch(batch_size).prefetch(1)
    return tfds.as_numpy(ds)





